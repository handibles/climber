---
title: 'shotgun metagenomics - setup'
author: 'IC / NPV / JFG'
date: "`r format(Sys.time(), '%d %b %Y, %H:%M')`"
output:
  html_document:
    toc: TRUE
  pdf_document: 
    toc: TRUE
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding=encoding, output_file='../documents/0.setup.html') })
---

`article in suspension`

<!-- > Please remember: -->

<!-- >  * when you login to the HPC, you must **always** change to a `node` before you do any work  -->

<!-- >  * you **must** be connected to the Teagasc network/VPN in order to access the  HPC. -->

<!-- >  * take notes, save your data, make backups, brush your teeth. -->


<!-- ---   -->

<!-- # 0 - setup your environment -->

<!-- It can be helpful to define any frequently used paths / values / variables at the start of your workflow, based on what you want to do. This keeps your workspace visible, easy to refer to, and allows you to reliably change the value throughout your work (e.g. a new project, a new database, etc.).  -->


<!-- #### organising your workspace -->

<!-- A good way to keep track of all your folders/files/values is to use **`$environmental_variables`** - these are temporary shortcuts added to `bash`'s working environment that tell the computer to replace the `$variable` with the file, folder, or value we have linked it to. For example, entering `PLAY=/home/user/Music/playlists` would create a new variable, `$PLAY`: when `$PLAY` is entered, the computer will spot the `$` character, understand that it's a shortcut, and replace that variable (`$PLAY`) with the value assigned to it (`/home/user/Music/playlists`) wherever that variable is found. -->

<!-- We will assign variables to the _folders_ you will use regularly, and for a _sample_ to use for testing things on. Feel free to change these to locations and/or names that make sense to you. Here `$CAPITALLETTERS` help keep these short words visible, but it's not necessary if you don't like shouting. Variables can use letters, numbers, and underscores (more [info on variables](https://ostechnix.com/bash-variables-shell-scripting/)). -->

<!-- We actually use these variables all time! Those created by the user ("user" variables) only last until you close the terminal window, or until a program or `for-loop` finishes (see `$i` in the for-loop section below!) - after this, they will be forgotten. Note that this means you have to enter these variables at each new session (there are clever ways of doing this too). A lot of other variables are created by the system ("system" variables) every time you open a new terminal window:  -->


<!-- ```{bash, eval= FALSE} -->
<!-- # $PATH tells the computer all the folders that have programs in them (multiple folder paths) -->
<!-- echo $PATH -->

<!-- # $HOME tells the computer where the user's home directory is (folder paths) -->
<!-- echo $HOME -->

<!-- # $TERM tells the computer what the default command-line interface is  (a value called by other programs) -->
<!-- echo $TERM -->

<!-- # $HISTSIZE tells the computer how many commands to remember (a value) -->
<!-- echo $HISTSIZE -->

<!-- # blah blah blah -->
<!-- ``` -->


<!-- #### Where does **my** data go? -->

<!-- Thank you for asking!   -->
<!-- **Remember, on the HPC:** -->

<!--   * **raw data** goes into the `primary` data directory (under your project name on the `hpc`) - here we give it the shortcut variable `$RAW`. This is your 'primary' data source, so do not edit it -->
<!--   * **output** data goes in the `analysis` folder. We set this variable shortcuts as `$WRK`, and all our output goes inside this dir.  -->


<!-- ```{bash, eval = FALSE} -->
<!-- # databases for different tools -->
<!-- DB=/data/data/databases -->
<!-- HGR38_BT=/data/databases/hostremoval/Homo_sapiens/Bowtie2/ -->
<!-- K2REFDIR=/data/databases/Kraken2_GTDB_r89_54k -->

<!-- # our overall data structure -->
<!-- RAW=/data/Food/primary/R0936_redcheese/ -->
<!-- WRK=/data/Food/analysis/R0936_redcheese/ -->

<!-- # scripts, and slurms for queueing up jobs -->
<!-- MAT=$WRK/Materials -->
<!-- SLURM=$WRK/slurms -->

<!-- # outputs etc -->
<!-- QC=$WRK/1__qc -->
<!-- FQC=$QC/fastqc -->
<!-- FILT=$WRK/2__filt -->
<!-- KDOUT=$WRK/3__knead -->
<!-- KROUT=$WRK/4__krak2 -->

<!-- #!# set a filename to test things on -->
<!-- TEST=SAMPLENAME -->

<!-- ``` -->

<!-- <!-- ```{bash, eval = FALSE} --> -->
<!-- <!-- # databases for different tools --> -->
<!-- <!-- DB=/home/jfg/data/ref --> -->
<!-- <!-- HGR38_BT=$DB/hg38 --> -->
<!-- <!-- K2REFDIR=$DB/Kraken2_GTDB_r89_54k --> -->

<!-- <!-- # our overall data structure --> -->
<!-- <!-- RAW=/home/jfg/data/raw/ms__sile_raw --> -->
<!-- <!-- WRK=/home/jfg/data/ferment/ms__sile --> -->

<!-- <!-- # scripts, and slurms for queueing up jobs --> -->
<!-- <!-- MAT=$WRK/Materials --> -->
<!-- <!-- SLURM=$WRK/slurms --> -->

<!-- <!-- # outputs etc --> -->
<!-- <!-- QC=$WRK/1__qc --> -->
<!-- <!-- FQC=$QC/fastqc --> -->
<!-- <!-- FILT=$WRK/2__filt --> -->
<!-- <!-- KDOUT=$WRK/3__knead --> -->
<!-- <!-- KROUT=$WRK/4__krak2 --> -->

<!-- <!-- #!# set a filename to test things on --> -->
<!-- <!-- TEST=ARG-Sam6_S41 --> -->

<!-- <!-- ``` --> -->


<!-- #### What tools do we need? -->

<!-- We will need to have [`FileZilla`](https://filezilla-project.org/download.php?type=client) (or similar) installed, as well as our `ssh` client (`putty`). -->

<!-- Next, we tell the HPC which programs we'll need, which are parcelled into "modules". If we don't load the modules, our session won't be able to "see" these programs in the `$PATH`. Some programs are always visible, others are loaded through e.g. `conda` and don't need to be mentioned here.  -->

<!--   * `FastQC` and `MultiQC` for quality control -->
<!--   * `Kraken2` for metagenomic community reconstruction -->
<!--   * `Kaiju`, also for metagenomic community reconstruction -->
<!--   * `GNU-parallel` for case where we can run many jobs in parallel. -->

<!-- ```{bash, eval = FALSE} -->
<!-- 	module load parallel fastqc multiqc kraken2 -->
<!-- ``` -->


<!-- #### Are we ready?  -->

<!-- Finally, we make sure that all the locations for the work we're doing exist! When we start, they won't exist yet (but note how the command looks up the full location for the directory): if `$QC` has not been defined, it will show you the contents of your current directory; if `$QC` _is_ defined, but hasnt been _created_ yet, it will tell you that the folder doesn't exist (which should be true!). -->
<!-- ```{bash, eval = FALSE} -->
<!-- ls $QC -->
<!-- ``` -->


<!-- In our unified data (`$RAW`) and work folders (`$WRK`), we create different folders for each output, using the variables above. It's not a problem if the folder already exists. -->

<!-- ```{bash, eval = FALSE} -->
<!-- 	# make analysis dirs -->
<!-- 	mkdir $RAW $WRK $FILT $QC $FQC $KDOUT $KROUT -->

<!-- 	# make script dirs etc. -->
<!-- 	mkdir $MAT $SLURM -->

<!--   # make dirs for qc outputs -->
<!-- 	mkdir $FQC/fhi_redch_raw $FQC/fhi_redch_trimm $FQC/multi_raw $FQC/multi_trimm -->
<!-- ``` -->

<!-- --- -->

<!-- # Reading / Reference -->

<!-- > [Linux command line for beginners](https://ubuntu.com/tutorials/command-line-for-beginners) - _quite quite good!_ -->

<!-- > [How to read an error](https://www.baeldung.com/linux/bash-errors) -->

<!-- > [info on variables](https://ostechnix.com/bash-variables-shell-scripting/) -->

