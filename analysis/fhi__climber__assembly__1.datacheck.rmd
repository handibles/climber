---
title: 'shotgun metagenomics - checking sequencing data'
author: 'IC / NPV / JFG'
date: "`r format(Sys.time(), '%d %b %Y, %H:%M')`"
output:
  html_document:
    toc: TRUE
  pdf_document: 
    toc: TRUE
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding=encoding, output_file='../documents/1.checkdata.html') })
---

`article in suspension`


<!-- # 1 - get the sequence data (& check) -->

<!-- We copied the data from IPLA-CSIC (or elsewhere!) manually, into the `$RAW` dir, using `FileZilla`. Sometimes we will have to use `scp`, `sFTP`, or `rsync` instead - a web search should show how to do this.  -->

<!-- Next, for our own information, we look at just the `fastq.gz` files, count the number of files, and run `FastQC` and `MultiQC` on them.  -->

<!-- ```{bash, eval = FALSE} -->
<!-- # use ls arguments "-lsh" to output it as an informative list -->
<!-- ls -lsh $RAW -->

<!-- # How many files? - use "|" charater to pipe the ls output to wc (wordcount), and count the n of lines (-l or --lines) -->
<!-- ls -lsh $RAW/*fastq.gz | wc -l -->

<!-- # can also easily check a fastq file -->
<!-- ls -lsh $RAW/$TEST*            # file details -->
<!-- zcat $RAW/$TEST* | head -10    # decompress, read and print top 10 lines -->
<!-- less -S $RAW/$TEST*            # read through file, press q to quit -->
<!-- ``` -->

<!-- ##### FastQC and MultiQC -->

<!-- `FastQC` is an amazingly useful tool, for profiling the quality, consistency, and content of your sequence data. It takes samples of each file it is shown (compressed or uncompressed), checks the sequences and returns a `HTML` & `zip` file for each `FASTQ`: the `HTML` is a report, and the `zip` is all the data from that report. Next, `MultiQC` combines all the `FastQC` outputs into one report, summarising all that info in one place. Always check this! -->

<!-- `FastQC` will process all `fastq(.qz)` files that it is passed. `MultiQC` will process all the `FastQC` outputs it finds in a directory, combine them, and place output in the dir specified (`multiqc_report.html` in `-o`). Keep in mind that `FastQC` and `MultiQC` outputs also contain text files of all this data (see the `multiqc_data` dir), if you want to use them for other graphics/reports etc. -->

<!-- #### Check sequence quality, with `FastQC`, on one sample: -->

<!-- ```{bash, eval = FALSE} -->
<!-- # then run a fastqc for F and R files, output in the dirs we made above -->
<!-- fastqc -t 4 $RAW/${TEST}* -o $FQC/fhi_redch_raw -->

<!-- # make a report that includes both F and R reads for this sample -->
<!-- multiqc $FQC/fhi_redch_raw -o $FQC/multi_raw -->
<!-- ``` -->

<!-- Copy the output `multiqc` files to your local computer, and doubleclick to open in your browser. For help reading `FastQC/MultiQC`, there's an [introductory tutorial video](https://www.youtube.com/watch?v=qPbIlO_KWN0) in the top of the `MultiQC` report. -->


<!-- #### Check sequence quality, with `FastQC`, on multiple sample: -->

<!-- We need to be responsible with our use of the HPC. Here we write a script in `slurm`(see the [HPC website](http://hcux400.teagasc.net/) for more info on `slurm`!!) format to queue all these jobs politely into one `FastQC` task, and then summarise using `MultiQC` again.  -->

<!-- We also found out that some `fasstq` files are compressed as `.gz`, and some are compressed at `.bz2`. This means that we need to specify both type fo `fastq` if we want it to work. Best way is to change our command to match both! We show the computer the two different compression types using the curly brackets: `{gz,bz2}`. This allows the computer to accept `*fastq.gz` and `fastq.bz2`: -->

<!-- ```{bash, eval = FALSE} -->
<!-- # write a slurm script first -->
<!-- echo '#!/bin/bash -->

<!-- SBATCH –job-name=knead_fastq -->
<!-- SBATCH –output=knead_fastq.txt -->

<!-- SBATCH –ntasks=15 -->
<!-- SBATCH –time=15:00 -->

<!-- IN=$1 -->
<!-- OUT=$2 -->

<!-- # time just tells us how long this takes, so we know for next time -->
<!-- # -t is the number of threads (tasks) to use -->
<!-- # curly brackets {} allow us to match either gz or bz2 file extensions -->
<!-- time fastqc -t 15 $IN/*fastq.{bz2,gz} -o $OUT -->
<!-- ' > $SLURM/slurm_fqc.sh -->

<!-- # review: -->
<!-- cat $SLURM/slurm_fqc.sh -->
<!-- ``` -->

<!-- This `slurm` script will give a name, output-log, runtime, and number of threads needed to the `slurm manager`, and use the input and output dirs we give to find `fastq.gz\bz2` files, start FastQC, and place outputs in the $OUT dir. We need to 'give' this `slurm` to `sbatch`: -->

<!-- **Note**: we have noticed that the `{}` brackets do not solve the problem of missing the `bz2` samples. We simply resubmitted the samples as `fastqc -t 4 $RAW/*fastq.bz2 -o $FQC/fhi_redch_raw` - this is not the right thing to do! -->

<!-- ```{bash, eval = FALSE} -->
<!-- # trust slurm -->
<!-- sbatch $SLURM/slurm_fqc.sh $RAW $FQC/fhi_redch_raw -->

<!-- # combine outputs -->
<!-- time multiqc $FQC/fhi_redch_raw -o $FQC/multi_raw -->

<!-- # then copy to local computer (try FileZilla), and open in your browser!  -->
<!-- ``` -->

<!-- Again, open the HTML report in your browser to see what the overall quality is like, and how much cleaning you will need to do. -->


<!-- #### Choosing your sample trimming parameters -->

<!-- With information on all the samples, it is possible (but not necessarily easy) to pick appropriate trimming and quality parameters.  -->

<!--   * Trimming of the `5'` end removes "artificial" bases at the start of `F+R` reads : check the FastQC or MultiQC outputs to see how long it takes for `Per-Base Sequence Content` to become homogeneous/balanced -->
<!--   * Trimming of the `3'` end removes bases where the sequencing quality declines gradually (especially the `R` reads) -->
<!--   * removing adapters removes synthetic sequences that were used to construct the sequencing library, but are not biological -->

<!-- Consider: How do the sequences look? Is quality uniform throughout, or does it vary? What other warnings (in red) do `FQC+MQC` detect? -->

<!-- --- -->

<!-- # Reading / Reference -->

<!-- > [FastQC site + support](https://duckduckgo.com/?q=fastqc&t=vivaldi&atb=v314-1&ia=web) - note that it's also available as an `R` library... -->

<!-- > [MultiQC site + support](https://multiqc.info) -->

<!-- > [slurm : examples of fancy job-queues for supercomputers like the `HPC`](https://www.marcc.jhu.edu/getting-started/additional-resources/distributing-tasks-with-slurm-and-gnu-parallel/) -->